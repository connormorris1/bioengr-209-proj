{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3653129/1912044137.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sa_svp_df['label'] = 1\n",
      "/tmp/ipykernel_3653129/1912044137.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sa_normal_df['label'] = 0\n"
     ]
    }
   ],
   "source": [
    "all_dicoms = pd.read_csv(\"/home/cjmorris/dicom_practice/pt_ids/all_dicom_headers.csv\")\n",
    "all_dicoms = all_dicoms.dropna(subset='SeriesDescription')\n",
    "svp_pids = list(pd.read_excel(\"/home/cjmorris/dicom_practice/pt_ids/95 SVP ground truth - HX.xlsx\")['ip_patient_id'])\n",
    "sa_df = all_dicoms[all_dicoms['SeriesDescription'].str.lower().str.contains('sa|short')]\n",
    "sa_df = sa_df[~sa_df['SeriesDescription'].str.lower().str.contains('sag|montage|valsalva|scout|flow_quant|cemra|mpr|shortt1|delay|t2starmap|trufi_loc|loc')] #trufi_loc, loc scans have no time dimension, but are otherwise good I think\n",
    "series_to_remove = ['tfl_loc_short-axis_iPAT','haste_sag','scout sa','scout SA','Cine SA montage','Delay_wideband SA_MAG','Delay_wideband SA_PSIR','MPR Ao sinuses of valsalva','MPR - sinuses of valsalva','T1Map_ShortT1_post1_19by60_MOCO','T1Map_ShortT1_post4_MOCO','T1Map_ShortT1_post3_27by60_MOCO','MPR LSA','MPR RSA','Thin mip rao gated sa_pf','Argus - EF SA Rpw','ShortIR_T1_T2map_bw1002_TR2.55_FA6_2','MPR Rt Basal','MPR gated SA','t2_tse_short axis','trufi2d_Real time SA_T-PAT3+']\n",
    "# bh_cine_sa_192i_25ph_2beat_1011v4_Normalized - seem to be unable to view dicoms with slicer? \n",
    "sa_df = sa_df[~sa_df['SeriesDescription'].isin(series_to_remove)]\n",
    "sa_df = sa_df[sa_df['num_frames'] >= 5]\n",
    "sa_svp_df = sa_df[sa_df['PatientID'].isin(svp_pids)]\n",
    "sa_svp_df['label'] = 1\n",
    "sa_normal_df = sa_df[~sa_df['PatientID'].isin(svp_pids)]\n",
    "sa_normal_df['label'] = 0\n",
    "svp_pids = list(sa_svp_df['PatientID'].unique())\n",
    "normal_pids = list(sa_normal_df['PatientID'].unique())\n",
    "train_svp_pids = random.sample(svp_pids,int(np.round(len(svp_pids)*0.8)))\n",
    "test_svp_pids = list(set(svp_pids) - set(train_svp_pids))\n",
    "train_normal_pids = random.sample(normal_pids,int(np.round(len(normal_pids)*0.8)))\n",
    "test_normal_pids = list(set(normal_pids) - set(train_normal_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svp_test_csv = pd.read_csv('data_paths/svp_test.csv',header=None)\n",
    "all_files = list(svp_test_csv[0])\n",
    "all_dirs = list(set([os.path.dirname(file) for file in all_files]))\n",
    "svp_test_df = sa_svp_df[sa_svp_df['sequence_path'].isin(all_dirs)]\n",
    "\n",
    "normal_test_csv = pd.read_csv('data_paths/normal_test.csv',header=None)\n",
    "all_files = list(normal_test_csv[0])\n",
    "all_dirs = list(set([os.path.dirname(file) for file in all_files]))\n",
    "normal_test_df = sa_normal_df[sa_normal_df['sequence_path'].isin(all_dirs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_loc_svp_test_df = pd.DataFrame(columns = [0,1]) \n",
    "for pid in svp_test_df['PatientID'].unique():\n",
    "    pdf = svp_test_df[svp_test_df['PatientID'] == pid]\n",
    "    for series in pdf['SeriesDescription'].unique():\n",
    "        sdf = pdf[pdf['SeriesDescription'] == series]\n",
    "        for date in sdf['Date'].unique():\n",
    "            ddf = sdf[sdf['Date'] == date]\n",
    "            all_times = dict()\n",
    "            all_loc = dict()\n",
    "            for dir in ddf['sequence_path'].unique():\n",
    "                all_dcm_filenames = os.listdir(dir)\n",
    "                dcm = dcmread(os.path.join(dir,all_dcm_filenames[0]))\n",
    "                loc = float(dcm.get((0x0021,0x1041),'Unknown').value)\n",
    "                all_loc[loc] = dir\n",
    "            all_loc_values = list(all_loc.keys())\n",
    "            upper_quartile = np.percentile(all_loc_values,75)\n",
    "            lower_loc_values = [x for x in all_loc_values if x < upper_quartile]\n",
    "            for val in lower_loc_values:\n",
    "                dir = all_loc[val]\n",
    "                for file in os.listdir(dir):\n",
    "                    med_loc_svp_test_df.loc[len(med_loc_svp_test_df)] = [os.path.join(dir,file),1]\n",
    "            # med_loc = np.median(all_loc_values)\n",
    "            # med_loc = min(all_loc_values, key=lambda x: abs(x - med_loc))\n",
    "            # test_dir = all_loc[med_loc]\n",
    "            # for file in os.listdir(test_dir):\n",
    "            #     dcm = dcmread(os.path.join(test_dir,file))\n",
    "\n",
    "                    # for filename in all_dcm_filenames:\n",
    "                    #     dcm = dcmread(os.path.join(dir,filename))\n",
    "                    #     time = dcm.TriggerTime\n",
    "                    #     all_times[time] = os.path.join(dir,filename)\n",
    "                    #     print(all_times)\n",
    "\n",
    "med_loc_normal_test_df = pd.DataFrame(columns = [0,1])\n",
    "for pid in normal_test_df['PatientID'].unique():\n",
    "    pdf = normal_test_df[normal_test_df['PatientID'] == pid]\n",
    "    for series in pdf['SeriesDescription'].unique():\n",
    "        sdf = pdf[pdf['SeriesDescription'] == series]\n",
    "        for date in sdf['Date'].unique():\n",
    "            ddf = sdf[sdf['Date'] == date]\n",
    "            all_times = dict()\n",
    "            all_loc = dict()\n",
    "            for dir in ddf['sequence_path'].unique():\n",
    "                all_dcm_filenames = os.listdir(dir)\n",
    "                dcm = dcmread(os.path.join(dir,all_dcm_filenames[0]))\n",
    "                loc = float(dcm.get((0x0020,0x1041),'Unknown').value)\n",
    "                all_loc[loc] = dir\n",
    "            all_loc_values = list(all_loc.keys())\n",
    "            bottom_quartile = np.percentile(all_loc_values,25)\n",
    "            upper_loc_values = [x for x in all_loc_values if x > bottom_quartile]\n",
    "            for val in upper_loc_values:\n",
    "                dir = all_loc[val]\n",
    "                for file in os.listdir(dir):\n",
    "                    med_loc_normal_test_df.loc[len(med_loc_normal_test_df)] = [os.path.join(dir,file),0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjmorris/miniconda3/envs/deep_learning/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cjmorris/miniconda3/envs/deep_learning/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#test new test dataset \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from CustomImageDataset import CustomImageDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from train_and_test_loop import train_loop, test_loop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import wandb\n",
    "upper_test_df = pd.concat([med_loc_svp_test_df,med_loc_normal_test_df])\n",
    "model_path = 'resnet_weights_longrun1.pth'\n",
    "model = models.resnet18(pretrained = False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1,bias=True) #***this model isn't built properly***\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_dataloader = DataLoader(CustomImageDataset(upper_test_df,224,False,file_is_df=True),batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      "   Accuracy: 0.850\n",
      "   recall: 0.559\n",
      "   specificity: 0.943\n",
      "   precision: 0.758\n",
      "   AUC: 0.893\n",
      "   Avg loss: 1.161674 \n",
      "\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/bioengr-209-proj/train_and_test_loop.py:81\u001b[0m, in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, loss_fn, device)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMismatch in # of examples used in evaluating model test performance.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Error: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   specificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Avg loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 81\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_acc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_precision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_recall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_specificity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mspecificity\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_auc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mauc\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader,model,criterion,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80730"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sa_normal_df)*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
